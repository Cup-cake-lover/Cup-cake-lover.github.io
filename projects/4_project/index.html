<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Learning from the Ising model! | Hari prasad SV </title> <meta name="author" content="Hari prasad SV"> <meta name="description" content="Boltzmann machine learning!"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%81&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cup-cake-lover.github.io/projects/4_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Hari</span> prasad SV </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About me </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">Talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Git </a> </li> <li class="nav-item "> <a class="nav-link" href="/resume/">Resume </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Learning from the Ising model!</h1> <p class="post-description">Boltzmann machine learning!</p> </header> <article> <h2 id="boltzmann-machine-learning">Boltzmann machine learning</h2> <p>Boltzmann machines are deeply connected to concepts from statistical mechanics, where equilibrium distributions and energy landscapes play central roles. By leveraging these connections, Boltzmann machines can model complex distributions, offering insights into both machine learning and physical systems. To understand the foundation of Boltzmann learning, we first explore the Ising model, a cornerstone in statistical physics.</p> <hr> <h2 id="the-ising-model">The Ising Model</h2> <p>The Ising model provides a framework to study the collective behavior of spins arranged on a lattice. Each spin, \(s_i\), can take one of two values, \(+1\) (up) or \(-1\) (down). Spins interact with their neighbors via pairwise couplings \(J_{ij}\), and the system may also be influenced by external fields \(h_i\). The Hamiltonian for a generalized spin glass system is:</p> \[\mathcal{H}(\{s_i\}) = -\sum_{j &gt; i} J_{ij} s_i s_j - \sum_{i} h_i s_i\] <p>Here:</p> <ul> <li>\(J_{ij}\): Interaction strength between spins \(s_i\) and \(s_j\).</li> <li>\(h_i\): External field acting on spin \(s_i\).</li> </ul> <p>This energy-based model encapsulates the interplay of spin alignments and external influences.</p> <hr> <h2 id="boltzmann-distribution-and-partition-function">Boltzmann Distribution and Partition Function</h2> <p>The Ising system’s equilibrium probability distribution is given by the Boltzmann distribution:</p> \[P_{J_{ij}, h_i}(\{s_i\}) = \frac{e^{-\mathcal{H}(\{s_i\})}}{\mathcal{Z}}\] <p>where the partition function, \(\mathcal{Z}\), ensures normalization:</p> \[\mathcal{Z} = \sum_{\{s_i\}} e^{-\mathcal{H}(\{s_i\})}\] <p>This distribution forms the basis for statistical inference, as it describes the likelihood of any spin configuration \(\{s_i\}\).</p> <hr> <h2 id="kullback-leibler-kl-divergence">Kullback-Leibler (KL) Divergence</h2> <p>To measure the difference between the model distribution \(P_\theta(S)\) (parameterized by \(\theta = \{J_{ij}, h_i\}\)) and the empirical distribution \(P_0(S)\), we use the Kullback-Leibler divergence:</p> \[D_{KL}(P_0 || P_\theta) = \sum_{\{s_i\}} P_0(\{s_i\}) \log \left( \frac{P_0(\{s_i\})}{P_\theta(\{s_i\})} \right)\] <p>Minimizing the KL divergence aligns the model distribution with the empirical data distribution.</p> <hr> <h2 id="deriving-the-loss-function">Deriving the Loss Function</h2> <p>The negative log-likelihood loss function measures how well the model \(P_\theta(\{s_i\})\) approximates the empirical distribution \(P_0(\{s_i\})\). It is derived as follows:</p> <p>The likelihood of the observed data under the model is:</p> \[\mathcal{L}(\theta) = -\frac{1}{M} \sum_{k=1}^M \log P_\theta(\{s_i^{(k)}\})\] <p>Substituting the Boltzmann distribution for \(P_\theta\), we get:</p> \[P_\theta(\{s_i\}) = \frac{e^{-\mathcal{H}(\{s_i\})}}{\mathcal{Z}}\] \[\log P_\theta(\{s_i\}) = -\mathcal{H}(\{s_i\}) - \log \mathcal{Z}\] <p>Thus, the negative log-likelihood becomes:</p> \[\mathcal{L}(\theta) = \frac{1}{M} \sum_{k=1}^M \mathcal{H}(\{s_i^{(k)}\}) + \log \mathcal{Z}\] <p>Here:</p> <ul> <li>The first term accounts for the energy of observed configurations.</li> <li>The second term, \(\log \mathcal{Z}\), is the log of the partition function, which depends on \(\theta\) and involves summing over all possible spin configurations.</li> </ul> <hr> <h2 id="gradient-of-the-loss-function">Gradient of the Loss Function</h2> <p>To optimize \(\mathcal{L}(\theta)\), we calculate the gradients with respect to \(h_i\) and \(J_{ij}\). For simplicity, denote \(\mathcal{L}(\theta)\) as \(\mathcal{L}\).</p> <p>Gradient w.r.t \(H_{i}\),</p> \[\frac{\partial \mathcal{L}}{\partial h_i} = \frac{\partial}{\partial h_i} \left( \frac{1}{M} \sum_{k=1}^M \mathcal{H}(\{s_i^{(k)}\}) + \log \mathcal{Z} \right)\] <p>Using \(\mathcal{H}(\{s_i\}) = -\sum_{j &gt; i} J_{ij} s_i s_j - \sum_i h_i s_i\), the derivative becomes:</p> \[\frac{\partial \mathcal{H}}{\partial h_i} = -s_i\] <p>Thus:</p> \[\frac{\partial \mathcal{L}}{\partial h_i} = -\frac{1}{M} \sum_{k=1}^M s_i^{(k)} + \frac{\partial \log \mathcal{Z}}{\partial h_i}\] <p>The partition function gradient is:</p> <p>\(\frac{\partial \log \mathcal{Z}}{\partial h_i} = \langle s_i \rangle_\theta\) Combining terms:</p> \[\frac{\partial \mathcal{L}}{\partial h_i} = \langle s_i \rangle_\theta - \langle s_i \rangle^D\] <p>Gradient w.r.t \(J_{ij}\)</p> \[\frac{\partial \mathcal{L}}{\partial J_{ij}} = -\frac{1}{M} \sum_{k=1}^M s_i^{(k)} s_j^{(k)} + \langle s_i s_j \rangle_\theta\] <hr> <h2 id="parameter-update-rules">Parameter Update Rules</h2> <p>Using gradient descent to minimize \(\mathcal{L}(\theta)\), the updates for \(h_i\) and \(J_{ij}\) are:</p> \[h_i^{n+1} = h_i^n + \eta \left( \langle s_i \rangle^D - \langle s_i \rangle_\theta \right)\] \[J_{ij}^{n+1} = J_{ij}^n + \eta \left( \langle s_i s_j \rangle^D - \langle s_i s_j \rangle_\theta \right)\] <p>where:</p> <ul> <li>\(\langle s_i \rangle^D\): Empirical average of \(s_i\) from data.</li> <li>\(\langle s_i \rangle_\theta\): Model average of \(s_i\) under the current parameters.</li> <li>\(\eta\): Learning rate controlling the update step size.</li> </ul> <hr> <p>The learning, in this case can be summarized as follows,</p> <ol> <li> <strong>Initialization</strong>: Start with random parameters \(h_i\) and \(J_{ij}\).</li> <li> <strong>Sampling</strong>: Generate model samples \(\{s_i\}\) using techniques like Gibbs sampling or contrastive divergence to approximate \(\langle s_i \rangle_\theta\) and \(\langle s_i s_j \rangle_\theta\).</li> <li> <strong>Compute Gradients</strong>: Use the empirical data to compute \(\langle s_i \rangle^D\) and \(\langle s_i s_j \rangle^D\), and calculate the gradients.</li> <li> <strong>Update Parameters</strong>: Adjust \(h_i\) and \(J_{ij}\) using the update rules.</li> <li> <strong>Iterate</strong>: Repeat until, where \(P_\theta(\{s_i\})\) closely matches the empirical \(P_0(\{s_i\})\).</li> </ol> <hr> <h2 id="implementation-in-python">Implementation in Python</h2> <p>Using the update rules mentioned above we can infer the target parameters. First we import neccessary libraries.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#import necessary packages.
</span><span class="kn">import</span> <span class="n">scienceplots</span> <span class="c1">#better plots
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span> <span class="p">;</span> <span class="kn">import</span> <span class="n">matplotlib</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span> 
<span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="n">matplotlib</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="sh">'</span><span class="s">figure.dpi</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="mi">200</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">([</span><span class="sh">'</span><span class="s">science</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">grid</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">no-latex</span><span class="sh">'</span><span class="p">])</span></code></pre></figure> <p>Define the one dimensional lattice and assign spins to it accordingly.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#Create random spin 1D chains
</span><span class="k">def</span> <span class="nf">init_lattice</span><span class="p">(</span><span class="n">L</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  args : L = lattice size (L)
  returns : ndarray shape L
  </span><span class="sh">'''</span>
  <span class="n">lattice</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="c1">##arrange [-1,+1] spins accordingly
</span>  <span class="k">return</span> <span class="n">lattice</span></code></pre></figure> <p>Now we need to create the target parameters that we are going to infer. To this end, we first create a function to create asymmetric and symmetric coupling matrix.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#Create target parameters that will be later inferred.
</span><span class="k">def</span> <span class="nf">create_target_params</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">assym</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  args : N = int, size of the interaction matrix , NxN and Nx1
         assym : flag = bool, set true for assymetric couplings.

  returns : ndarray with shapes NxN and Nx1
  
  </span><span class="sh">'''</span>  
  <span class="k">if</span> <span class="n">assym</span><span class="o">==</span><span class="bp">False</span><span class="p">:</span>
    <span class="n">temp_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="o">/</span><span class="n">N</span><span class="p">,(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">))</span>
    <span class="n">J</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">temp_matrix</span> <span class="o">+</span> <span class="n">temp_matrix</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="p">;</span> <span class="n">np</span><span class="p">.</span><span class="nf">fill_diagonal</span><span class="p">(</span><span class="n">J</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># symmetric matrix with zero diagonal
</span>    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span> 

  <span class="k">else</span><span class="p">:</span>
    <span class="n">J</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="o">/</span><span class="n">N</span><span class="p">,(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">))</span> <span class="p">;</span>  <span class="c1"># Assymetric matrix
</span>    <span class="n">np</span><span class="p">.</span><span class="nf">fill_diagonal</span><span class="p">(</span><span class="n">J</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="n">J</span><span class="p">,</span><span class="n">h</span></code></pre></figure> <p>Now we need to create a system which is thermalized. To do this, we thermalize the system using a Markov Chain - Monte Carlo (MCMC). A metropolis-Hastings step is performed in each markov step.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#Calculate energy difference.
</span>
<span class="k">def</span> <span class="nf">calculate_energy_diff</span><span class="p">(</span><span class="n">temp_index</span><span class="p">,</span><span class="n">configuration</span><span class="p">,</span><span class="n">J</span><span class="p">,</span><span class="n">h</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  args : temp_index = int, temporary index for placeholder
         configuration = ndarray Nx1, spin configuration
         J = ndarray NxN, interaction matrix 
         h = ndarray Nx1, external field.

  return : E, float, energy difference between spin flip
  
  </span><span class="sh">'''</span>
    
  <span class="n">E</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">configuration</span><span class="p">[</span><span class="n">temp_index</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">J</span><span class="p">[</span><span class="n">temp_index</span><span class="p">,:],</span><span class="n">configuration</span><span class="p">)</span> <span class="o">+</span> <span class="n">h</span><span class="p">[</span><span class="n">temp_index</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">E</span>


<span class="c1">#Metropolis dynamics.
</span> 
<span class="k">def</span> <span class="nf">metropolis_dynamics</span><span class="p">(</span><span class="n">lattice</span><span class="p">,</span><span class="n">J</span><span class="p">,</span><span class="n">h</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  args : lattice = ndarray Nx1 , spin configuration 
         J = ndarray NxN, interaction matrix 
         h = ndarray Nx1, external field. 
         
  returns : configuration = ndarray Nx1, updated configuration
  </span><span class="sh">'''</span> 
    
  <span class="n">configuration</span> <span class="o">=</span> <span class="n">lattice</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span> <span class="p">;</span> <span class="n">L</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">configuration</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">lattice</span><span class="p">)):</span>
    <span class="n">random_index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">L</span><span class="p">)</span>
    <span class="n">delta_E</span> <span class="o">=</span> <span class="nf">calculate_energy_diff</span><span class="p">(</span><span class="n">random_index</span><span class="p">,</span><span class="n">configuration</span><span class="p">,</span><span class="n">J</span><span class="p">,</span><span class="n">h</span><span class="p">)</span>

    <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">delta_E</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">prob</span><span class="p">:</span>
      <span class="n">configuration</span><span class="p">[</span><span class="n">random_index</span><span class="p">]</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>

  <span class="k">return</span> <span class="n">configuration</span></code></pre></figure> <p>Now we perform MCMC,</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#Perform markov chain monte carlo.
</span><span class="k">def</span> <span class="nf">markovchain_montecarlo</span><span class="p">(</span><span class="n">lattice</span><span class="p">,</span><span class="n">J</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">sweeps</span><span class="p">,</span><span class="n">burn_in</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  args : lattice = ndarray Nx1 , spin configuration 
         J = ndarray NxN, interaction matrix 
         h = ndarray Nx1, external field
         sweeps = int, number of sweeps
         burn_in = int, number of burn_in sweeps

  returns : mag = ndarray Nx1 , Mean Magnetisations
            C_ij = ndarray NxN, correlation matrix
            states = ndarray Nxsweeps, Final spins states.
  </span><span class="sh">'''</span>
    
    
  <span class="n">configuration</span> <span class="o">=</span> <span class="n">lattice</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span> <span class="p">;</span> <span class="n">L</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">lattice</span><span class="p">)</span>
  <span class="n">C_ij</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">L</span><span class="p">,</span><span class="n">L</span><span class="p">))</span>
  <span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">burn_in</span><span class="p">):</span>
    <span class="n">configuration</span> <span class="o">=</span> <span class="nf">metropolis_dynamics</span><span class="p">(</span><span class="n">configuration</span><span class="p">,</span><span class="n">J</span><span class="p">,</span><span class="n">h</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">sweep</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">sweeps</span><span class="p">):</span>
    <span class="n">configuration</span> <span class="o">=</span> <span class="nf">metropolis_dynamics</span><span class="p">(</span><span class="n">configuration</span><span class="p">,</span><span class="n">J</span><span class="p">,</span><span class="n">h</span><span class="p">)</span>
    <span class="n">C_ij</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="nf">outer</span><span class="p">(</span><span class="n">configuration</span><span class="p">,</span><span class="n">configuration</span><span class="p">)</span>
    <span class="n">states</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>

  <span class="n">mag</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">states</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">C_ij</span> <span class="o">/=</span> <span class="n">sweeps</span>

  <span class="k">return</span> <span class="n">mag</span><span class="p">,</span><span class="n">C_ij</span><span class="p">,</span><span class="n">states</span></code></pre></figure> <p>Note that we are saving both Magnetisations, and Spin-Spin correlations. The <code class="language-plaintext highlighter-rouge">states</code> will be used to find the empirical probability distribution and in turn to find the negative log likelihood.</p> <p>To check if the system thermalizes and to calculate the ‘burn-in’ time, we let the system runs with a range of values.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">J</span><span class="p">,</span><span class="n">h</span> <span class="o">=</span> <span class="nf">create_target_params</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">lattice</span> <span class="o">=</span> <span class="nf">init_lattice</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">sweeps</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="n">burn_in_steps</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="c1"># Make a list of burn in values
</span><span class="n">burn_ins</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">burn_in_steps</span> <span class="c1">#
</span>
<span class="n">L</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">lattice</span><span class="p">)</span>

<span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">burn_ins</span><span class="p">),</span> <span class="n">L</span> <span class="p">))</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="nf">len</span><span class="p">(</span><span class="n">burn_ins</span><span class="p">),</span> <span class="n">L</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">burn_ins</span><span class="p">)):</span>
  <span class="n">mag</span><span class="p">,</span><span class="n">C_ij</span><span class="p">,</span><span class="n">states</span> <span class="o">=</span> <span class="nf">markovchain_montecarlo</span><span class="p">(</span><span class="n">lattice</span><span class="p">,</span><span class="n">J</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">burn_ins</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">mag</span>
  <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">C_ij</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()</span>

<span class="c1">#Take their differences so that it can be plotted.
</span><span class="n">Mags</span> <span class="o">=</span> <span class="nf">abs</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">diff</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> 
<span class="n">Corrs</span> <span class="o">=</span> <span class="nf">abs</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">diff</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span></code></pre></figure> <p>If we plot the results we see it clearly.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Boltzmann_plots/Thermalisations_boltzmann-480.webp 480w,/assets/img/Boltzmann_plots/Thermalisations_boltzmann-800.webp 800w,/assets/img/Boltzmann_plots/Thermalisations_boltzmann-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Boltzmann_plots/Thermalisations_boltzmann.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Example result" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Thermalisation check. </div> <p>Now we create neccessary functions to calculate some key parameters. First we need to observe how the learning process. To do this, we can calculate the negative log likelihood (NLL). To do this, we use the previously calculated spin configuration vectors.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#Calculate Negative log likelihood
</span><span class="k">def</span> <span class="nf">calculate_NLL</span><span class="p">(</span><span class="n">configs</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">
    args : configs, list, list of final states obtained.
    returns : NLL, float, Negative log likelihood
    </span><span class="sh">'''</span>
    <span class="n">M</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
    <span class="n">unique_samples</span><span class="p">,</span> <span class="n">sample_counts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">configs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">Prob_distr</span> <span class="o">=</span> <span class="n">sample_counts</span> <span class="o">/</span> <span class="n">M</span>
    <span class="n">NLL</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">M</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">sample_counts</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">Prob_distr</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">NLL</span></code></pre></figure> <p>Now we define the update steps for \(h\) and \(J\).</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Update schemes
</span><span class="k">def</span> <span class="nf">h_update</span><span class="p">(</span><span class="n">h</span><span class="p">,</span><span class="n">mag_model</span><span class="p">,</span><span class="n">mag_train</span><span class="p">,</span><span class="n">eta</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  args : h = ndarray Nx1, external fields  
         mag_model = ndarray Nx1, Model magnetistaions
         mag_train = ndarray Nx1, training data
         eta = float, learning rate.

  returns : h_up = ndarray Nx1, updated parameter values 
  </span><span class="sh">'''</span>  
    
  <span class="n">h_up</span> <span class="o">=</span> <span class="n">h</span> <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="n">mag_train</span> <span class="o">-</span> <span class="n">mag_model</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">h_up</span>

<span class="k">def</span> <span class="nf">J_update</span><span class="p">(</span><span class="n">J</span><span class="p">,</span><span class="n">corr_model</span><span class="p">,</span><span class="n">corr_train</span><span class="p">,</span><span class="n">eta</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  args : J = ndarray NxN, interaction matrix  
         corr_model = ndarray NxN, Model correlations
         corr_train = ndarray NxN, training data
         eta = float, learning rate.

  returns : J_up = ndarray NxN, updated parameter values 
  </span><span class="sh">'''</span>    
  <span class="n">J_up</span> <span class="o">=</span> <span class="n">J</span> <span class="o">+</span> <span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="n">corr_train</span> <span class="o">-</span> <span class="n">corr_model</span><span class="p">)</span>
  <span class="n">np</span><span class="p">.</span><span class="nf">fill_diagonal</span><span class="p">(</span><span class="n">J_up</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">J_up</span></code></pre></figure> <p>After the update schemes are defined, the final learning loop can be constructed.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#Main learning block
</span><span class="k">def</span> <span class="nf">boltzmann_machine</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">iterations</span><span class="p">,</span><span class="n">sweeps</span><span class="p">,</span><span class="n">burn_in</span><span class="p">,</span><span class="n">mag_train</span><span class="p">,</span><span class="n">corr_train</span><span class="p">,</span><span class="n">eta</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  args : 
         L = int, size of the spin configuration chain
         iterations = int, number of iterations
         sweeps = int, number of markov sweeps
         burn_in = int, number of burn_in sweeps
         mag_train = ndarray Nx1, training data
         corr_train = ndarray NxN, training data
         eta = float, learning rate.

  returns : J = ndarray NxN, inferred interaction matrix
            h = ndarray Nx1, inferred field
            log_likelihoods = list, Negative log likelihoods
  </span><span class="sh">'''</span>  

    
  <span class="n">J</span><span class="p">,</span><span class="n">h</span> <span class="o">=</span> <span class="nf">create_target_params</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
  <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">)):</span>
    <span class="n">mag_model</span><span class="p">,</span><span class="n">corr_model</span><span class="p">,</span><span class="n">states</span> <span class="o">=</span> <span class="nf">markovchain_montecarlo</span><span class="p">(</span><span class="nf">init_lattice</span><span class="p">(</span><span class="n">L</span><span class="p">),</span><span class="n">J</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">sweeps</span><span class="p">,</span><span class="n">burn_in</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="nf">h_update</span><span class="p">(</span><span class="n">h</span><span class="p">,</span><span class="n">mag_model</span><span class="p">,</span><span class="n">mag_train</span><span class="p">,</span><span class="n">eta</span><span class="p">)</span>
    <span class="n">J</span> <span class="o">=</span> <span class="nc">J_update</span><span class="p">(</span><span class="n">J</span><span class="p">,</span><span class="n">corr_model</span><span class="p">,</span><span class="n">corr_train</span><span class="p">,</span><span class="n">eta</span><span class="p">)</span>
    <span class="n">NLL</span> <span class="o">=</span> <span class="nf">calculate_NLL</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
    <span class="n">log_likelihoods</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">NLL</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">J</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">log_likelihoods</span></code></pre></figure> <p>Done! now all we have to do see if all of this works, is to generaete some sample values for \(h\) and \(J\), thermalize the system and we can infer those generated values. Here I am plotting the learning process by varying \(\eta\), the learning rate.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Boltzmann_plots/NLL_etas_boltzmann-480.webp 480w,/assets/img/Boltzmann_plots/NLL_etas_boltzmann-800.webp 800w,/assets/img/Boltzmann_plots/NLL_etas_boltzmann-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Boltzmann_plots/NLL_etas_boltzmann.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Example result" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Negative log likelihood for different learning rates. </div> <p>The inferred parameters look like this,</p> <div class="row"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Boltzmann_plots/J_etas_boltzmann-480.webp 480w,/assets/img/Boltzmann_plots/J_etas_boltzmann-800.webp 800w,/assets/img/Boltzmann_plots/J_etas_boltzmann-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Boltzmann_plots/J_etas_boltzmann.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Example result 1" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Boltzmann_plots/h_etas_boltzmann-480.webp 480w,/assets/img/Boltzmann_plots/h_etas_boltzmann-800.webp 800w,/assets/img/Boltzmann_plots/h_etas_boltzmann-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/Boltzmann_plots/h_etas_boltzmann.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Example result 2" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> J and h inferred and actual values. </div> <p>Note that \(J\) was a 5x5 matrix, so it is flattened to look at the inference.</p> <p>Thumbnail image credits:</p> <p>By <a href="//commons.wikimedia.org/w/index.php?title=User:HeMath&amp;action=edit&amp;redlink=1" class="new" title="User:HeMath (page does not exist)">HeMath</a> - <span class="int-own-work" lang="en">Own work</span>, <a href="https://creativecommons.org/licenses/by-sa/4.0" title="Creative Commons Attribution-Share Alike 4.0" rel="external nofollow noopener" target="_blank">CC BY-SA 4.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=37327967" rel="external nofollow noopener" target="_blank">Link</a></p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Hari prasad SV. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about-me",title:"About me",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"Publications",description:"A list of my publications",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"Projects",description:"Feel free to browse through some of my projects. I am still in the process of formatting and adding detailed versions of some of them!",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-talks",title:"Talks",description:"These are some of the presentations I gave as part of course work and otherwise.",section:"Navigation",handler:()=>{window.location.href="/talks/"}},{id:"nav-git",title:"Git",description:"You can find my details of my github profile @Cup-cake-lover here!.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-resume",title:"Resume",description:"Here you can find my resume, a detailed pdf version is also available on the link.",section:"Navigation",handler:()=>{window.location.href="/resume/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"news-i-started-my-master-s-program-at-the-university-of-cologne",title:"I started my master\u2019s program at the University of Cologne.",description:"",section:"News"},{id:"news-started-my-internship-position-at-forschungzentrum-j\xfclich-j\xfclich-germany",title:"Started my internship position at Forschungzentrum-J\xfclich, J\xfclich, Germany.",description:"",section:"News"},{id:"news-ended-my-internship-position-at-forschungzentrum-j\xfclich-j\xfclich-germany",title:"Ended my internship position at Forschungzentrum-J\xfclich, J\xfclich, Germany.",description:"",section:"News"},{id:"news-co-organized-the-bonn-cologne-graduate-school-weekened-seminar-2025-at-the-dpg-physikzentrum-bad-honnef-from-07-02-to-09-02",title:"Co-organized the Bonn Cologne Graduate School Weekened Seminar 2025 at the DPG Physikzentrum,...",description:"",section:"News"},{id:"projects-neural-synchrony",title:"Neural synchrony.",description:"Simulating synchrony in brain --&gt; The hard way!",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-trees-are-shy",title:"Trees are shy.",description:"Simulating crown/canopy shyness in trees!",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-learning-from-the-ising-model",title:"Learning from the Ising model!",description:"Boltzmann machine learning!",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-epilepsy-detection-using-non-linear-feature-analysis",title:"Epilepsy Detection Using Non-Linear Feature Analysis",description:"A baseline setup",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%68%70%76%61%72%69%79%61%72@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>